import os
import time
import wave
import threading
from .sdk import VoiceToTextSDK
from .init import ChatWithHistory

OUTPUT_DIR = "./temp_audio"
os.makedirs(OUTPUT_DIR, exist_ok=True)

class SpeechProcessor:
    def __init__(self, sdk: VoiceToTextSDK, chat: ChatWithHistory):
        self.sdk = sdk
        self.chat = chat
        self.audio_file_count = 0
        self.tts_was_interrupted = False

    def process_speech(self, audio_path, interrupted):
        print(f"ğŸ¤ å¼€å§‹å¤„ç†è¯­éŸ³: {audio_path}")
        try:
            recognized_text = self.sdk.transcribe_audio(audio_path)
            print(f'ğŸ“ è¯†åˆ«ç»“æœ: "{recognized_text}" (æ‰“æ–­çŠ¶æ€: {interrupted})')

            if recognized_text:
                if interrupted:
                    print("ğŸ”´ TTSè¢«æ‰“æ–­ï¼Œä»…è®°å½•æ–‡æœ¬ï¼Œä¸ç”Ÿæˆå›å¤")
                else:
                    print("ğŸ¤– æ­£åœ¨ç”Ÿæˆå›å¤...")
                    response_text = self.chat.get_response(recognized_text)
                    print(f"ğŸ’¬ å›å¤å†…å®¹: {response_text}")
                    # åœ¨è¿™é‡Œæ·»åŠ TTSæ’­æ”¾é€»è¾‘
            else:
                print("ğŸ¤·â€â™€ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬")
        except Exception as e:
            print(f"âŒ å¤„ç†è¯­éŸ³æ—¶å‡ºé”™: {e}")
        finally:
            try:
                os.remove(audio_path)
            except:
                pass

    def extract_and_process_speech_segment(self, continuous_audio_buffer, start_time, end_time, recording_start_time, pre_post_buffer_seconds):
        extract_start = max(start_time - pre_post_buffer_seconds, recording_start_time)
        extract_end = end_time + pre_post_buffer_seconds

        print(f"ğŸ“ æˆªå–éŸ³é¢‘ç‰‡æ®µ: {extract_start:.2f} - {extract_end:.2f} (åŸè¯­éŸ³: {start_time:.2f} - {end_time:.2f})")

        extracted_audio = [audio_data for audio_data, timestamp in continuous_audio_buffer if extract_start <= timestamp <= extract_end]

        if not extracted_audio:
            print("âŒ æœªæ‰¾åˆ°å¯¹åº”æ—¶é—´æ®µçš„éŸ³é¢‘æ•°æ®")
            return

        self.audio_file_count += 1
        audio_output_path = f"{OUTPUT_DIR}/speech_{time.strftime('%Y%m%d_%H%M%S')}_{self.audio_file_count:03d}.wav"

        try:
            with wave.open(audio_output_path, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(16000)
                wf.writeframes(b''.join(extracted_audio))
            print(f"ğŸ’¾ éŸ³é¢‘ç‰‡æ®µä¿å­˜è‡³ {audio_output_path}")

            current_interruption_status = self.tts_was_interrupted
            inference_thread = threading.Thread(target=self.process_speech, args=(audio_output_path, current_interruption_status))
            inference_thread.start()
            self.tts_was_interrupted = False
        except Exception as e:
            print(f"âŒ ä¿å­˜æˆ–å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {e}")